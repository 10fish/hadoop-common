Hadoop MapReduce Change Log

Trunk (unreleased changes)

  INCOMPATIBLE CHANGES

    MAPREDUCE-516. Fix the starvation problem in the Capacity Scheduler 
    when running High RAM Jobs. (Arun Murthy via yhemanth)

    MAPREDUCE-358. Change org.apache.hadoop.examples. AggregateWordCount 
    and org.apache.hadoop.examples.AggregateWordHistogram to use new 
    mapreduce api. (Amareshwari Sriramadasu via sharad)

  NEW FEATURES

    MAPREDUCE-551. Preemption support in the Fair Scheduler. (Matei Zaharia)

    HADOOP-5887. Sqoop should create tables in Hive metastore after importing
    to HDFS. (Aaron Kimball via tomwhite)

    MAPREDUCE-567. Add a new example MR that always fails. (Philip Zeyliger
    via tomwhite)

  IMPROVEMENTS

    HADOOP-5967. Sqoop should only use a single map task. (Aaron Kimball via
    tomwhite)

    HADOOP-5968. Sqoop should only print a warning about mysql import speed
    once. (Aaron Kimball via tomwhite)

    MAPREDUCE-463. Makes job setup and cleanup tasks as optional.
    (Amareshwari Sriramadasu via sharad)

    MAPREDUCE-502. Allow jobtracker to be configured with zero completed jobs
    in memory. (Amar Kamat via sharad)

  BUG FIXES
    HADOOP-4687. MapReduce is split from Hadoop Core. It is a subproject under 
    Hadoop (Owen O'Malley)

    HADOOP-6096. Fix Eclipse project and classpath files following project
    split. (tomwhite)

    MAPREDUCE-419. Reconcile mapred.userlog.limit.kb defaults in configuration
    and code. (Philip Zeyliger via cdouglas)

    MAPREDUCE-2. Fixes a bug in KeyFieldBasedPartitioner in handling empty
    keys. (Amar Kamat via sharad)

    MAPREDUCE-130. Delete the jobconf copy from the log directory of the 
    JobTracker when the job is retired. (Amar Kamat via sharad)

    MAPREDUCE-657. Fix hardcoded filesystem problem in CompletedJobStatusStore.
    (Amar Kamat via sharad)

    MAPREDUCE-179. Update progress in new RecordReaders. (cdouglas)

    MAPREDUCE-658. Replace NPE in distcp with a meaningful error message when
    the source path does not exist. (Ravi Gummadi via cdouglas)
